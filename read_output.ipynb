{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('is36': conda)"
  },
  "interpreter": {
   "hash": "94de5f854492d881c1090ba2bada37ea5a224138e31d2f0053a25cfed357f2e6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# output_folder = 'data/output/'\n",
    "output_folder = '/Users/nus/hg-core-decomposition/backup_output/mpi/data/output/'\n",
    "# output_folder = 'run_1/mpi/data/output/'\n",
    "# output_folder = 'run_2(mac)/data/output/'\n",
    "\n",
    "# If fig folder exists remove it and its contents recursively\n",
    "if os.path.exists(output_folder+\"fig/\"):\n",
    "    shutil.rmtree(output_folder+\"fig/\")\n",
    "os.mkdir(output_folder+\"fig/\")\n",
    "\n",
    "fontsize = 22\n",
    "labelsize = 18"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "# output_folder2 = '/Users/nus/hg-core-decomposition/backup_output/mpi/data/output/'\n",
    "output_folder2 = '/Users/nus/hg-core-decomposition/run_par/mpi/data/output/'\n",
    "df2 = pd.read_csv(output_folder2+\"result.csv\")\n",
    "df2.columns = ['algo', 'bucket update time', 'core', 'dataset', 'degree call time', 'execution time', 'init time', 'inner iteration', 'neighborhood call time', 'num bucket update', 'num degree computation', 'num neighborhood computation', 'num subgraph call', 'num_threads', 'outerloop time', 'param_s', 'subgraph computation time', 'total iteration']\n",
    "df2 = df2.loc[df2['algo'].isin(['naive_nbr','improved_nbr'])]\n",
    "df2.shape\n",
    "# df2.head()\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(70, 18)"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "source": [
    "# df = pd.read_csv(\"data/output/result.csv\", header=None)\n",
    "df = pd.read_csv(output_folder+\"result.csv\")\n",
    "df.columns = ['algo', 'bucket update time', 'core', 'dataset', 'degree call time', 'execution time', 'init time', 'inner iteration', 'neighborhood call time', 'num bucket update', 'num degree computation', 'num neighborhood computation', 'num subgraph call', 'num_threads', 'outerloop time', 'param_s', 'subgraph computation time', 'total iteration']\n",
    "print(df.shape)\n",
    "# df.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4154, 18)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# df = pd.concat([df,df2])\n",
    "# df.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# # df = pd.read_csv(\"data/output/result.csv\", header=None)\n",
    "# df = pd.read_csv(output_folder+\"result.csv\")\n",
    "# df.columns = ['algo', 'bucket update time', 'core', 'dataset', 'degree call time', 'execution time', 'neighborhood call time', 'num bucket update', 'num degree computation', 'num neighborhood computation', 'param_s']\n",
    "# print(df.shape)\n",
    "# # df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### sample plotting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "source": [
    "save = True\n",
    "\n",
    "\n",
    "sns.set(rc={'figure.figsize':(7,4)})\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : True})\n",
    "\n",
    "columns = ['bucket update time', 'execution time', 'init time', 'inner iteration', 'neighborhood call time', 'num bucket update', 'num neighborhood computation', 'num subgraph call', 'outerloop time',  'subgraph computation time', 'total iteration']\n",
    "good_name = {\n",
    "    'bucket update time' : 'Bucket time (s)', \n",
    "    'execution time' : \"Time (s)\", \n",
    "    'neighborhood call time' : \"NB time (s)\", \n",
    "    'subgraph computation time' : \"Sub time(s)\",\n",
    "    'num bucket update' : \"#bucket\", \n",
    "    'num neighborhood computation' : \"#nb\",\n",
    "    'num subgraph call' : \"#subgraph\",\n",
    "    'outerloop time': \"outloop time(s)\",\n",
    "    'init time': 'init time(s)',\n",
    "    'total iteration': '#total iterations',\n",
    "    'inner iteration': '#inner iterations',\n",
    "    # 'num_threads' : '#Threads'\n",
    "}\n",
    "\n",
    "good_name_algo = {\n",
    "    'naive_nbr' : \"NBR\", \n",
    "    'improved_nbr' : \"NBR(1)\", \n",
    "    'improved2_nbr' : \"NBR(2)\",\n",
    "    'par_improved2_nbr' : \"pNBR(2)\",\n",
    "    'par_improved3_nbr' : \"pNBR(3)\",\n",
    "    'naive_degree' : \"DEG\"\n",
    "}\n",
    "\n",
    "group_list = ['dataset']\n",
    "for key, item in df.groupby(group_list, as_index=False):\n",
    "    # key contains dataset\n",
    "    item['param_s'] = item['param_s'].astype(int)\n",
    "    item = item.replace({\"algo\": good_name_algo})\n",
    "    for y_axis in columns:\n",
    "\n",
    "        sns.barplot(x='algo', y=y_axis, data=item, palette='colorblind', order=['NBR', 'NBR(1)', 'NBR(2)',\"pNBR(2)\",\"pNBR(3)\"])\n",
    "        plt.xlabel('Algorithm', fontsize=fontsize)\n",
    "        plt.ylabel(good_name[y_axis], fontsize=fontsize)\n",
    "        # plt.yscale(\"log\")\n",
    "        plt.xticks(fontsize=labelsize)\n",
    "        plt.yticks(fontsize=labelsize)\n",
    "        plt.title(key)\n",
    "        plt.tight_layout()\n",
    "        filename = (key + \" \" + y_axis).replace(\" \", \"_\")\n",
    "        if(save):\n",
    "            plt.savefig(output_folder+\"fig/\" + filename + \".pdf\")\n",
    "        else:\n",
    "            print(filename)\n",
    "            plt.show()\n",
    "        plt.clf()\n",
    "\n",
    "    # Commnet out following to see full results\n",
    "    if(not save):\n",
    "        break"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 504x288 with 0 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Effect of parameter \"s\" in improved2_nbr"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "source": [
    "save = True\n",
    "\n",
    "if(save):\n",
    "    os.system(\"mkdir -p \" + output_folder+\"fig/param_s/\" )\n",
    "\n",
    "group_list = ['dataset']\n",
    "for key, item in df[df['algo'] == 'improved2_nbr'].groupby(group_list, as_index=False):\n",
    "    \n",
    "    # key contains dataset\n",
    "    item['param_s'] = item['param_s'].astype(int)\n",
    "\n",
    "    for y_axis in ['bucket update time', 'execution time', 'neighborhood call time', 'num bucket update', 'num neighborhood computation','subgraph computation time','outerloop time', 'init time']:\n",
    "\n",
    "        sns.barplot(x='param_s', y=y_axis, data=item, palette='colorblind')\n",
    "        plt.xlabel(r'$s$', fontsize=fontsize)\n",
    "        plt.ylabel(good_name[y_axis], fontsize=fontsize)\n",
    "        # plt.yscale(\"log\")\n",
    "        # plt.xticks(rotation=45)\n",
    "        plt.xticks(fontsize=labelsize)\n",
    "        plt.yticks(fontsize=labelsize)\n",
    "\n",
    "        plt.title(key)\n",
    "        # plt.legend(loc='best', fontsize=labelsize-4)\n",
    "        plt.tight_layout()\n",
    "        filename = (key + \" param_s \" + y_axis).replace(\" \", \"_\")\n",
    "        if(save):\n",
    "            plt.savefig(output_folder+\"fig/param_s/\" + filename + \".pdf\")\n",
    "        else:\n",
    "            print(filename)\n",
    "            plt.show()\n",
    "        plt.clf()\n",
    "\n",
    "    # Commnet out following to see full results\n",
    "    if(not save):\n",
    "        break\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 504x288 with 0 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Effect of threads for parallel algorithms"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "save = True\n",
    "sns.set(rc={'figure.figsize':(7,4)})\n",
    "if(save):\n",
    "    os.system(\"mkdir -p \" + output_folder+\"fig/num_threads/\" )\n",
    "\n",
    "\n",
    "group_list = ['dataset','algo']\n",
    "for key, item in df[df['algo'].isin(['par_improved2_nbr', 'par_improved3_nbr'])].groupby(group_list, as_index=False):\n",
    "    # key contains dataset\n",
    "    item['num_threads'] = item['num_threads'].astype(int)\n",
    "    \n",
    "    for y_axis in ['bucket update time', 'execution time', 'neighborhood call time', 'num bucket update', 'num neighborhood computation','subgraph computation time','outerloop time', 'init time']:\n",
    "        sns.barplot(x='num_threads', y=y_axis, data=item, palette='colorblind')\n",
    "        plt.xlabel('#Threads', fontsize=fontsize)\n",
    "        plt.ylabel(y_axis, fontsize=fontsize)\n",
    "        # plt.yscale(\"log\")\n",
    "        # plt.xticks(rotation=45)\n",
    "        plt.xticks(fontsize=labelsize)\n",
    "        plt.yticks(fontsize=labelsize)\n",
    "        # print(key)\n",
    "        plt.title(key[0] + \"_\" + good_name_algo[key[1]])\n",
    "        plt.title(key)\n",
    "        # plt.legend(loc='best', fontsize=labelsize-4)\n",
    "        plt.tight_layout()\n",
    "        filename = (key[0] + \"_\" + good_name_algo[key[1]] + \" num threads \" + y_axis).replace(\" \", \"_\")\n",
    "        # filename = key+\"_\"+y_axis\n",
    "        if(save):\n",
    "            plt.savefig(output_folder+\"fig/num_threads/\" + filename + \".pdf\")\n",
    "        else:\n",
    "            print(filename)\n",
    "            plt.show()\n",
    "        plt.clf()\n",
    "\n",
    "    # Commnet out following to see full results\n",
    "    if(not save):\n",
    "        break\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 504x288 with 0 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "both algorithm by thread together\n",
    "--------------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "source": [
    "save = True\n",
    "sns.set(rc={'figure.figsize':(7,4)})\n",
    "if(save):\n",
    "    os.system(\"mkdir -p \" + output_folder+\"fig/num_threads/\" )\n",
    "\n",
    "\n",
    "group_list = ['dataset']\n",
    "for key, item in df[df['algo'].isin(['par_improved2_nbr', 'par_improved3_nbr'])].groupby(group_list, as_index=False):\n",
    "    # key contains dataset\n",
    "    item['num_threads'] = item['num_threads'].astype(int)\n",
    "    \n",
    "    for y_axis in ['bucket update time', 'execution time', 'neighborhood call time', 'num bucket update', 'num neighborhood computation','subgraph computation time','outerloop time', 'init time']:\n",
    "        dat = item[['num_threads',y_axis,'algo']]\n",
    "        dat = dat.melt(id_vars=['num_threads','algo'])\n",
    "        # print(dat.head(10))\n",
    "        # break\n",
    "        sns.barplot(x='num_threads', y='value', hue='algo', data= dat, palette='colorblind')\n",
    "        # sns.barplot(x='num_threads', y=y_axis, data=item, palette='colorblind')\n",
    "        plt.xlabel('#Threads', fontsize=fontsize)\n",
    "        plt.ylabel(y_axis, fontsize=fontsize)\n",
    "        # plt.yscale(\"log\")\n",
    "        # plt.xticks(rotation=45)\n",
    "        plt.xticks(fontsize=labelsize)\n",
    "        plt.yticks(fontsize=labelsize)\n",
    "        # print(key)\n",
    "        # plt.title(key[0] + \"_\" + good_name_algo[key[1]])\n",
    "        plt.title(key)\n",
    "        # plt.legend(loc='best', fontsize=labelsize-4)\n",
    "        plt.tight_layout()\n",
    "        # filename = (key[0] + \"_\" + good_name_algo[key[1]] + \" num threads \" + y_axis).replace(\" \", \"_\")\n",
    "        filename = key+\"_\"+y_axis\n",
    "        if(save):\n",
    "            plt.savefig(output_folder+\"fig/num_threads/\" + filename + \".pdf\")\n",
    "        else:\n",
    "            print(filename)\n",
    "            plt.show()\n",
    "        plt.clf()\n",
    "\n",
    "    # Commnet out following to see full results\n",
    "    if(not save):\n",
    "        break"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 504x288 with 0 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "df.columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['algo', 'bucket update time', 'core', 'dataset', 'degree call time',\n",
       "       'execution time', 'neighborhood call time', 'num bucket update',\n",
       "       'num degree computation', 'num neighborhood computation', 'param_s'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### statistics of run"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "group_list = ['dataset', 'algo', 'param_s']\n",
    "for key, item in df.groupby(group_list, as_index=False):\n",
    "    print(key, item.shape[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('default', 'improved2_nbr', 16.0) 100\n",
      "('default', 'improved_nbr', 13.0) 100\n",
      "('default', 'naive_degree', 13.0) 100\n",
      "('default', 'naive_nbr', 1.0) 100\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# df[(df['algo'] == \"improved2_nbr\") & (df['dataset'] == 'bin_4') & (df['param_s'] == 6)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "%Time spent on subgraph computation\n",
    "-----------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "save = True\n",
    "\n",
    "\n",
    "sns.set(rc={'figure.figsize':(5,4)})\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : True})\n",
    "\n",
    "\n",
    "\n",
    "good_name = {\n",
    "    'bucket update time' : 'Bucket time (s)', \n",
    "    'execution time' : \"Time (s)\", \n",
    "    'neighborhood call time' : \"NB time (s)\", \n",
    "    'subgraph computation time' : \"Sub time(s)\",\n",
    "    'num bucket update' : \"#bucket\", \n",
    "    'num neighborhood computation' : \"#nb\",\n",
    "    'num subgraph call' : \"#subgraph\",\n",
    "    'ratio(subg.time,total)': \"subgtime/total\"\n",
    "}\n",
    "\n",
    "good_name_algo = {\n",
    "    'naive_nbr' : \"NBR\", \n",
    "    'improved_nbr' : \"NBR(1)\", \n",
    "    'improved2_nbr' : \"NBR(2)\",\n",
    "    'naive_degree' : \"DEG\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "df['ratio(subg.time,total)'] = df['subgraph computation time']/df['execution time']\n",
    "group_list = ['dataset']\n",
    "for key, item in df.groupby(group_list, as_index=False):\n",
    "    # key contains dataset\n",
    "    item['param_s'] = item['param_s'].astype(int)\n",
    "    item = item.replace({\"algo\": good_name_algo})\n",
    "    # item['ratio(subg.time,total)'] = item['subgraph computation time']/item['execution time']\n",
    "    # print(item[['execution time',  'subgraph computation time','ratio(subg.time,total)']].head())\n",
    "    for y_axis in ['ratio(subg.time,total)']:\n",
    "\n",
    "        sns.barplot(x='algo', y=y_axis, data=item, palette='colorblind', order=['NBR', 'NBR(1)', 'NBR(2)'])\n",
    "        plt.xlabel('Algorithm', fontsize=fontsize)\n",
    "        plt.ylabel(good_name[y_axis], fontsize=fontsize)\n",
    "        # plt.yscale(\"log\")\n",
    "        plt.xticks(fontsize=labelsize)\n",
    "        plt.yticks(fontsize=labelsize)\n",
    "        plt.title(key)\n",
    "        plt.tight_layout()\n",
    "        filename = (key + \" \" + y_axis).replace(\" \", \"_\")\n",
    "        if(save):\n",
    "            plt.savefig(output_folder+\"fig/\" + filename + \".pdf\")\n",
    "        else:\n",
    "            print(filename)\n",
    "            plt.show()\n",
    "        plt.clf()\n",
    "\n",
    "    # Commnet out following to see full results\n",
    "    if(not save):\n",
    "        break"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 360x216 with 0 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Distribution of core-numbers.\n",
    "-----------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "import ast\n",
    "\n",
    "# save = True\n",
    "\n",
    "\n",
    "sns.set(rc={'figure.figsize':(5,4)})\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : True})\n",
    "\n",
    "\n",
    "\n",
    "good_name = {\n",
    "    'bucket update time' : 'Bucket time (s)', \n",
    "    'execution time' : \"Time (s)\", \n",
    "    'neighborhood call time' : \"NB time (s)\", \n",
    "    'subgraph computation time' : \"Sub time(s)\",\n",
    "    'num bucket update' : \"#bucket\", \n",
    "    'num neighborhood computation' : \"#nb\",\n",
    "    'num subgraph call' : \"#subgraph\"\n",
    "}\n",
    "\n",
    "good_name_algo = {\n",
    "    'naive_nbr' : \"NBR\", \n",
    "    'improved_nbr' : \"NBR(1)\", \n",
    "    'improved2_nbr' : \"NBR(2)\",\n",
    "    'naive_degree' : \"DEG\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "group_list = ['dataset']\n",
    "\n",
    "for key, item in df.groupby(group_list, as_index=False):\n",
    "    # key contains dataset\n",
    "    # item['param_s'] = item['param_s'].astype(int)\n",
    "    item = item.replace({\"algo\": good_name_algo})\n",
    "    \n",
    "    nbr_distr = {}\n",
    "    core = ast.literal_eval(item[item['algo'] == 'NBR'].iloc[0].core)\n",
    "    N = len(core)\n",
    "    for node_id, core_num in core.items():\n",
    "        nbr_distr[core_num] = nbr_distr.get(core_num,0) + 1/N \n",
    "    \n",
    "    x = range(1,max(nbr_distr.keys())+1)\n",
    "    y = [ nbr_distr.get(i,0) for i in x]\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(x,y, marker = 'o')\n",
    "    plt.xlabel('nbr-core number')\n",
    "    plt.ylabel('fraction of vertices')\n",
    "    plt.title(key)\n",
    "    plt.savefig(output_folder+\"fig/\"+'nbrcore_'+key+'.pdf',bbox_inches = 'tight')\n",
    "    plt.close() \n",
    "\n",
    "    deg_distr = {}\n",
    "    core = ast.literal_eval(item[item['algo'] == 'DEG'].iloc[0].core)\n",
    "    N = len(core)\n",
    "    for node_id, core_num in core.items():\n",
    "        deg_distr[core_num] = deg_distr.get(core_num,0)+ 1/N \n",
    "    x = range(1,max(deg_distr.keys())+1)\n",
    "    y = [ deg_distr.get(i,0) for i in x]\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(x,y,marker = 'o')\n",
    "    plt.xlabel('deg-core number')\n",
    "    plt.ylabel('fraction of vertices')\n",
    "    plt.title(key)\n",
    "    plt.savefig(output_folder+\"fig/\"+'degcore_'+key+'.pdf',bbox_inches = 'tight')\n",
    "    plt.close()\n",
    "    # for y_axis in ['bucket update time', 'execution time', 'neighborhood call time', 'num bucket update', 'num neighborhood computation', 'subgraph computation time', 'num subgraph call']:\n",
    "\n",
    "    #     sns.barplot(x='algo', y=y_axis, data=item, palette='colorblind', order=['NBR', 'NBR(1)', 'NBR(2)'])\n",
    "    #     plt.xlabel('Algorithm', fontsize=fontsize)\n",
    "    #     plt.ylabel(good_name[y_axis], fontsize=fontsize)\n",
    "    #     # plt.yscale(\"log\")\n",
    "    #     plt.xticks(fontsize=labelsize)\n",
    "    #     plt.yticks(fontsize=labelsize)\n",
    "    #     plt.title(key)\n",
    "    #     plt.tight_layout()\n",
    "    #     filename = (key + \" \" + y_axis).replace(\" \", \"_\")\n",
    "    #     if(save):\n",
    "    #         plt.savefig(output_folder+\"fig/\" + filename + \".pdf\")\n",
    "    #     else:\n",
    "    #         print(filename)\n",
    "    #         plt.show()\n",
    "    #     plt.clf()\n",
    "\n",
    "    # Commnet out following to see full results\n",
    "    # if(not save):\n",
    "    #     break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "dummy cell"
   ],
   "metadata": {}
  }
 ]
}