{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "f2b1d5c1238215474af997a65570577ac58d66d27940243aa0cec70a6942441c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "output_folder = 'data/output/'\n",
    "# output_folder = '/Users/nus/hg-core-decomposition/backup_output/mpi/data/output/'\n",
    "# output_folder = 'run_1/mpi/data/output/'\n",
    "# output_folder = 'run_2(mac)/data/output/'\n",
    "\n",
    "# If fig folder exists remove it and its contents recursively\n",
    "if os.path.exists(output_folder+\"fig/\"):\n",
    "    shutil.rmtree(output_folder+\"fig/\")\n",
    "os.mkdir(output_folder+\"fig/\")\n",
    "\n",
    "fontsize = 22\n",
    "labelsize = 18"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# output_folder2 = '/Users/nus/hg-core-decomposition/backup_output/mpi/data/output/'\n",
    "# output_folder2 = '/Users/nus/hg-core-decomposition/run_par/mpi/data/output/'\n",
    "# df2 = pd.read_csv(output_folder2+\"result.csv\")\n",
    "# df2.columns = ['algo', 'bucket update time', 'core', 'dataset', 'degree call time', 'execution time', 'init time', 'inner iteration', 'neighborhood call time', 'num bucket update', 'num degree computation', 'num neighborhood computation', 'num subgraph call', 'num_threads', 'outerloop time', 'param_s', 'subgraph computation time', 'total iteration']\n",
    "# df2 = df2.loc[df2['algo'].isin(['naive_nbr','improved_nbr'])]\n",
    "# df2.shape\n",
    "# df2.head()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# df = pd.read_csv(\"data/output/result.csv\", header=None)\n",
    "df = pd.read_csv(output_folder+\"result.csv\")\n",
    "df.columns = ['algo', 'bucket update time', 'core', 'core_correction time', 'dataset', 'degree call time', 'execution time', 'init time', 'inner iteration', 'memory taken', 'neighborhood call time', 'num bucket update', 'num degree computation', 'num neighborhood computation', 'num subgraph call', 'num_threads', 'outerloop time', 'param_s', 'subgraph computation time', 'total iteration']\n",
    "# df.columns = ['algo', 'bucket update time', 'core', 'dataset', 'degree call time', 'execution time', 'init time', 'inner iteration', 'neighborhood call time', 'num bucket update', 'num degree computation', 'num neighborhood computation', 'num subgraph call', 'num_threads', 'outerloop time', 'param_s', 'subgraph computation time', 'total iteration']\n",
    "# df.columns = ['algo', 'bucket update time', 'core', 'dataset', 'degree call time', 'execution time', 'init time', 'inner iteration', 'memory taken', 'neighborhood call time', 'num bucket update', 'num degree computation', 'num neighborhood computation', 'num subgraph call', 'num_threads', 'outerloop time', 'param_s', 'subgraph computation time', 'total iteration']\n",
    "print(df.shape)\n",
    "# df.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(371, 20)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df = pd.concat([df,df2])\n",
    "df.shape"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df2' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7efe7cb104d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df2' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# # df = pd.read_csv(\"data/output/result.csv\", header=None)\n",
    "# df = pd.read_csv(output_folder+\"result.csv\")\n",
    "# df.columns = ['algo', 'bucket update time', 'core', 'dataset', 'degree call time', 'execution time', 'neighborhood call time', 'num bucket update', 'num degree computation', 'num neighborhood computation', 'param_s']\n",
    "# print(df.shape)\n",
    "# # df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### sample plotting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "save = True\n",
    "\n",
    "\n",
    "sns.set(rc={'figure.figsize':(7,4)})\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : True})\n",
    "\n",
    "columns = ['bucket update time', 'execution time', 'init time', 'inner iteration', 'memory taken', 'neighborhood call time', 'num bucket update', 'num neighborhood computation', 'num subgraph call', 'outerloop time',  'subgraph computation time', 'total iteration']\n",
    "good_name = {\n",
    "    'bucket update time' : 'Bucket time (s)', \n",
    "    'execution time' : \"Time (s)\", \n",
    "    'neighborhood call time' : \"NB time (s)\", \n",
    "    'subgraph computation time' : \"Sub time(s)\",\n",
    "    'num bucket update' : \"#bucket\", \n",
    "    'num neighborhood computation' : \"#nb\",\n",
    "    'num subgraph call' : \"#subgraph\",\n",
    "    'outerloop time': \"outloop time(s)\",\n",
    "    'init time': 'init time(s)',\n",
    "    'total iteration': '#total iterations',\n",
    "    'inner iteration': '#inner iterations',\n",
    "    'memory taken': 'Memory(MB)'\n",
    "    # 'num_threads' : '#Threads'\n",
    "}\n",
    "\n",
    "good_name_algo = {\n",
    "    'naive_nbr' : \"NBR\", \n",
    "    'improved_nbr' : \"NBR(1)\", \n",
    "    'local_core': \"LOCAL\",\n",
    "    'par_local_core': \"LOCAL(p)\",\n",
    "    'improved_nbr_simple':'NBR1s',\n",
    "    'improved2_nbr' : \"NBR(2)\",\n",
    "    'par_improved2_nbr' : \"pNBR(2)\",\n",
    "    'par_improved3_nbr' : \"pNBR(3)\",\n",
    "    'naive_degree' : \"DEG\"\n",
    "}\n",
    "\n",
    "# ['NBR', 'NBR(1)', 'NBR1s', 'NBR(2)',\"pNBR(2)\",\"pNBR(3)\"]\n",
    "group_list = ['dataset']\n",
    "for key, item in df.groupby(group_list, as_index=False):\n",
    "    # key contains dataset\n",
    "    item['param_s'] = item['param_s'].astype(int)\n",
    "    item = item.replace({\"algo\": good_name_algo})\n",
    "    for y_axis in columns:\n",
    "\n",
    "        sns.barplot(x='algo', y=y_axis, data=item, palette='colorblind', order=['NBR', 'NBR(1)','LOCAL', 'LOCAL(p)'])\n",
    "        plt.xlabel('Algorithm', fontsize=fontsize)\n",
    "        plt.ylabel(good_name[y_axis], fontsize=fontsize)\n",
    "        # plt.yscale(\"log\")\n",
    "        plt.xticks(fontsize=labelsize)\n",
    "        plt.yticks(fontsize=labelsize)\n",
    "        plt.title(key)\n",
    "        plt.tight_layout()\n",
    "        filename = (key + \" \" + y_axis).replace(\" \", \"_\")\n",
    "        if(save):\n",
    "            plt.savefig(output_folder+\"fig/\" + filename + \".pdf\")\n",
    "        else:\n",
    "            print(filename)\n",
    "            plt.show()\n",
    "        plt.clf()\n",
    "\n",
    "    # Commnet out following to see full results\n",
    "    if(not save):\n",
    "        break"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 504x288 with 0 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Effect of parameter \"s\" in improved2_nbr"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "source": [
    "save = True\n",
    "\n",
    "if(save):\n",
    "    os.system(\"mkdir -p \" + output_folder+\"fig/param_s/\" )\n",
    "\n",
    "group_list = ['dataset']\n",
    "for key, item in df[df['algo'] == 'improved2_nbr'].groupby(group_list, as_index=False):\n",
    "    \n",
    "    # key contains dataset\n",
    "    item['param_s'] = item['param_s'].astype(int)\n",
    "\n",
    "    for y_axis in ['bucket update time', 'execution time', 'neighborhood call time', 'num bucket update', 'num neighborhood computation','subgraph computation time','outerloop time', 'init time']:\n",
    "\n",
    "        sns.barplot(x='param_s', y=y_axis, data=item, palette='colorblind')\n",
    "        plt.xlabel(r'$s$', fontsize=fontsize)\n",
    "        plt.ylabel(good_name[y_axis], fontsize=fontsize)\n",
    "        # plt.yscale(\"log\")\n",
    "        # plt.xticks(rotation=45)\n",
    "        plt.xticks(fontsize=labelsize)\n",
    "        plt.yticks(fontsize=labelsize)\n",
    "\n",
    "        plt.title(key)\n",
    "        # plt.legend(loc='best', fontsize=labelsize-4)\n",
    "        plt.tight_layout()\n",
    "        filename = (key + \" param_s \" + y_axis).replace(\" \", \"_\")\n",
    "        if(save):\n",
    "            plt.savefig(output_folder+\"fig/param_s/\" + filename + \".pdf\")\n",
    "        else:\n",
    "            print(filename)\n",
    "            plt.show()\n",
    "        plt.clf()\n",
    "\n",
    "    # Commnet out following to see full results\n",
    "    if(not save):\n",
    "        break\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 504x288 with 0 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Effect of threads for parallel algorithms"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "save = True\n",
    "sns.set(rc={'figure.figsize':(7,4)})\n",
    "if(save):\n",
    "    os.system(\"mkdir -p \" + output_folder+\"fig/num_threads/\" )\n",
    "\n",
    "# algorithms = ['par_improved2_nbr', 'par_improved3_nbr']\n",
    "algorithms = ['par_local_core']\n",
    "group_list = ['dataset','algo']\n",
    "for key, item in df[df['algo'].isin(algorithms)].groupby(group_list, as_index=False):\n",
    "    # key contains dataset\n",
    "    item['num_threads'] = item['num_threads'].astype(int)\n",
    "    \n",
    "    for y_axis in ['bucket update time', 'execution time', 'neighborhood call time', 'num bucket update', 'num neighborhood computation','subgraph computation time','outerloop time', 'init time']:\n",
    "        sns.barplot(x='num_threads', y=y_axis, data=item, palette='colorblind')\n",
    "        plt.xlabel('#Threads', fontsize=fontsize)\n",
    "        plt.ylabel(y_axis, fontsize=fontsize)\n",
    "        # plt.yscale(\"log\")\n",
    "        # plt.xticks(rotation=45)\n",
    "        plt.xticks(fontsize=labelsize)\n",
    "        plt.yticks(fontsize=labelsize)\n",
    "        # print(key)\n",
    "        plt.title(key[0] + \"_\" + good_name_algo[key[1]])\n",
    "        plt.title(key)\n",
    "        # plt.legend(loc='best', fontsize=labelsize-4)\n",
    "        plt.tight_layout()\n",
    "        filename = (key[0] + \"_\" + good_name_algo[key[1]] + \" num threads \" + y_axis).replace(\" \", \"_\")\n",
    "        # filename = key+\"_\"+y_axis\n",
    "        if(save):\n",
    "            plt.savefig(output_folder+\"fig/num_threads/\" + filename + \".pdf\")\n",
    "        else:\n",
    "            print(filename)\n",
    "            plt.show()\n",
    "        plt.clf()\n",
    "\n",
    "    # Commnet out following to see full results\n",
    "    if(not save):\n",
    "        break\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 504x288 with 0 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Effect of threads for parallel algorithms (multiple barplots)\n",
    "--------------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "source": [
    "save = True\n",
    "sns.set(rc={'figure.figsize':(7,4)})\n",
    "if(save):\n",
    "    os.system(\"mkdir -p \" + output_folder+\"fig/num_threads/\" )\n",
    "\n",
    "\n",
    "group_list = ['dataset']\n",
    "for key, item in df[df['algo'].isin(['par_improved2_nbr', 'par_improved3_nbr'])].groupby(group_list, as_index=False):\n",
    "    # key contains dataset\n",
    "    item['num_threads'] = item['num_threads'].astype(int)\n",
    "    \n",
    "    for y_axis in ['bucket update time', 'execution time', 'neighborhood call time', 'num bucket update', 'num neighborhood computation','subgraph computation time','outerloop time', 'init time']:\n",
    "        dat = item[['num_threads',y_axis,'algo']]\n",
    "        dat = dat.melt(id_vars=['num_threads','algo'])\n",
    "        # print(dat.head(10))\n",
    "        # break\n",
    "        sns.barplot(x='num_threads', y='value', hue='algo', data= dat, palette='colorblind')\n",
    "        # sns.barplot(x='num_threads', y=y_axis, data=item, palette='colorblind')\n",
    "        plt.xlabel('#Threads', fontsize=fontsize)\n",
    "        plt.ylabel(y_axis, fontsize=fontsize)\n",
    "        # plt.yscale(\"log\")\n",
    "        # plt.xticks(rotation=45)\n",
    "        plt.xticks(fontsize=labelsize)\n",
    "        plt.yticks(fontsize=labelsize)\n",
    "        # print(key)\n",
    "        # plt.title(key[0] + \"_\" + good_name_algo[key[1]])\n",
    "        plt.title(key)\n",
    "        # plt.legend(loc='best', fontsize=labelsize-4)\n",
    "        plt.tight_layout()\n",
    "        # filename = (key[0] + \"_\" + good_name_algo[key[1]] + \" num threads \" + y_axis).replace(\" \", \"_\")\n",
    "        filename = key+\"_\"+y_axis\n",
    "        if(save):\n",
    "            plt.savefig(output_folder+\"fig/num_threads/\" + filename + \".pdf\")\n",
    "        else:\n",
    "            print(filename)\n",
    "            plt.show()\n",
    "        plt.clf()\n",
    "\n",
    "    # Commnet out following to see full results\n",
    "    if(not save):\n",
    "        break"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 504x288 with 0 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "df.columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['algo', 'bucket update time', 'core', 'dataset', 'degree call time',\n",
       "       'execution time', 'neighborhood call time', 'num bucket update',\n",
       "       'num degree computation', 'num neighborhood computation', 'param_s'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### statistics of run"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "group_list = ['dataset', 'algo', 'param_s']\n",
    "for key, item in df.groupby(group_list, as_index=False):\n",
    "    print(key, item.shape[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('default', 'improved2_nbr', 16.0) 100\n",
      "('default', 'improved_nbr', 13.0) 100\n",
      "('default', 'naive_degree', 13.0) 100\n",
      "('default', 'naive_nbr', 1.0) 100\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# df[(df['algo'] == \"improved2_nbr\") & (df['dataset'] == 'bin_4') & (df['param_s'] == 6)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "%Time spent on subgraph computation\n",
    "-----------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "save = True\n",
    "\n",
    "\n",
    "sns.set(rc={'figure.figsize':(5,4)})\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : True})\n",
    "\n",
    "\n",
    "\n",
    "good_name = {\n",
    "    'bucket update time' : 'Bucket time (s)', \n",
    "    'execution time' : \"Time (s)\", \n",
    "    'neighborhood call time' : \"NB time (s)\", \n",
    "    'subgraph computation time' : \"Sub time(s)\",\n",
    "    'num bucket update' : \"#bucket\", \n",
    "    'num neighborhood computation' : \"#nb\",\n",
    "    'num subgraph call' : \"#subgraph\",\n",
    "    'ratio(subg.time,total)': \"subgtime/total\"\n",
    "}\n",
    "\n",
    "good_name_algo = {\n",
    "    'naive_nbr' : \"NBR\", \n",
    "    'improved_nbr' : \"NBR(1)\", \n",
    "    'improved2_nbr' : \"NBR(2)\",\n",
    "    'naive_degree' : \"DEG\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "df['ratio(subg.time,total)'] = df['subgraph computation time']/df['execution time']\n",
    "group_list = ['dataset']\n",
    "for key, item in df.groupby(group_list, as_index=False):\n",
    "    # key contains dataset\n",
    "    item['param_s'] = item['param_s'].astype(int)\n",
    "    item = item.replace({\"algo\": good_name_algo})\n",
    "    # item['ratio(subg.time,total)'] = item['subgraph computation time']/item['execution time']\n",
    "    # print(item[['execution time',  'subgraph computation time','ratio(subg.time,total)']].head())\n",
    "    for y_axis in ['ratio(subg.time,total)']:\n",
    "\n",
    "        sns.barplot(x='algo', y=y_axis, data=item, palette='colorblind', order=['NBR', 'NBR(1)', 'NBR(2)'])\n",
    "        plt.xlabel('Algorithm', fontsize=fontsize)\n",
    "        plt.ylabel(good_name[y_axis], fontsize=fontsize)\n",
    "        # plt.yscale(\"log\")\n",
    "        plt.xticks(fontsize=labelsize)\n",
    "        plt.yticks(fontsize=labelsize)\n",
    "        plt.title(key)\n",
    "        plt.tight_layout()\n",
    "        filename = (key + \" \" + y_axis).replace(\" \", \"_\")\n",
    "        if(save):\n",
    "            plt.savefig(output_folder+\"fig/\" + filename + \".pdf\")\n",
    "        else:\n",
    "            print(filename)\n",
    "            plt.show()\n",
    "        plt.clf()\n",
    "\n",
    "    # Commnet out following to see full results\n",
    "    if(not save):\n",
    "        break"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 360x216 with 0 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Distribution of core-numbers.\n",
    "-----------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "import ast\n",
    "\n",
    "# save = True\n",
    "\n",
    "\n",
    "sns.set(rc={'figure.figsize':(5,4)})\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : True})\n",
    "\n",
    "\n",
    "\n",
    "good_name = {\n",
    "    'bucket update time' : 'Bucket time (s)', \n",
    "    'execution time' : \"Time (s)\", \n",
    "    'neighborhood call time' : \"NB time (s)\", \n",
    "    'subgraph computation time' : \"Sub time(s)\",\n",
    "    'num bucket update' : \"#bucket\", \n",
    "    'num neighborhood computation' : \"#nb\",\n",
    "    'num subgraph call' : \"#subgraph\"\n",
    "}\n",
    "\n",
    "good_name_algo = {\n",
    "    'naive_nbr' : \"NBR\", \n",
    "    'improved_nbr' : \"NBR(1)\", \n",
    "    'improved2_nbr' : \"NBR(2)\",\n",
    "    'naive_degree' : \"DEG\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "group_list = ['dataset']\n",
    "\n",
    "for key, item in df.groupby(group_list, as_index=False):\n",
    "    # key contains dataset\n",
    "    # item['param_s'] = item['param_s'].astype(int)\n",
    "    item = item.replace({\"algo\": good_name_algo})\n",
    "    \n",
    "    nbr_distr = {}\n",
    "    core = ast.literal_eval(item[item['algo'] == 'NBR'].iloc[0].core)\n",
    "    N = len(core)\n",
    "    for node_id, core_num in core.items():\n",
    "        nbr_distr[core_num] = nbr_distr.get(core_num,0) + 1/N \n",
    "    \n",
    "    x = range(1,max(nbr_distr.keys())+1)\n",
    "    y = [ nbr_distr.get(i,0) for i in x]\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(x,y, marker = 'o')\n",
    "    plt.xlabel('nbr-core number')\n",
    "    plt.ylabel('fraction of vertices')\n",
    "    plt.title(key)\n",
    "    plt.savefig(output_folder+\"fig/\"+'nbrcore_'+key+'.pdf',bbox_inches = 'tight')\n",
    "    plt.close() \n",
    "\n",
    "    deg_distr = {}\n",
    "    core = ast.literal_eval(item[item['algo'] == 'DEG'].iloc[0].core)\n",
    "    N = len(core)\n",
    "    for node_id, core_num in core.items():\n",
    "        deg_distr[core_num] = deg_distr.get(core_num,0)+ 1/N \n",
    "    x = range(1,max(deg_distr.keys())+1)\n",
    "    y = [ deg_distr.get(i,0) for i in x]\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(x,y,marker = 'o')\n",
    "    plt.xlabel('deg-core number')\n",
    "    plt.ylabel('fraction of vertices')\n",
    "    plt.title(key)\n",
    "    plt.savefig(output_folder+\"fig/\"+'degcore_'+key+'.pdf',bbox_inches = 'tight')\n",
    "    plt.close()\n",
    "    # for y_axis in ['bucket update time', 'execution time', 'neighborhood call time', 'num bucket update', 'num neighborhood computation', 'subgraph computation time', 'num subgraph call']:\n",
    "\n",
    "    #     sns.barplot(x='algo', y=y_axis, data=item, palette='colorblind', order=['NBR', 'NBR(1)', 'NBR(2)'])\n",
    "    #     plt.xlabel('Algorithm', fontsize=fontsize)\n",
    "    #     plt.ylabel(good_name[y_axis], fontsize=fontsize)\n",
    "    #     # plt.yscale(\"log\")\n",
    "    #     plt.xticks(fontsize=labelsize)\n",
    "    #     plt.yticks(fontsize=labelsize)\n",
    "    #     plt.title(key)\n",
    "    #     plt.tight_layout()\n",
    "    #     filename = (key + \" \" + y_axis).replace(\" \", \"_\")\n",
    "    #     if(save):\n",
    "    #         plt.savefig(output_folder+\"fig/\" + filename + \".pdf\")\n",
    "    #     else:\n",
    "    #         print(filename)\n",
    "    #         plt.show()\n",
    "    #     plt.clf()\n",
    "\n",
    "    # Commnet out following to see full results\n",
    "    # if(not save):\n",
    "    #     break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df.iloc[1].core"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-49b36bc38aee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/is36/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/is36/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/is36/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1435\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1437\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[0;31m# -------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "dummy cell"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pandemic propagation results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from ast import literal_eval\n",
    "import shutil\n",
    "\n",
    "output_folder = 'data/output/'\n",
    "if os.path.exists(output_folder+\"fig/\"):\n",
    "    shutil.rmtree(output_folder+\"fig/\")\n",
    "os.mkdir(output_folder+\"fig/\")\n",
    "\n",
    "fontsize = 22\n",
    "labelsize = 18"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df = pd.read_csv(output_folder + \"propagation_result.csv\", header=None)\n",
    "df.columns = ['algo', 'dataset', 'p', 'result']\n",
    "print(df.shape)\n",
    "df\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(10, 4)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo</th>\n",
       "      <th>dataset</th>\n",
       "      <th>p</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naive_nbr</td>\n",
       "      <td>default</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{1: [0.07692307692307687, 0.07692307692307687,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>naive_nbr</td>\n",
       "      <td>default</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{1: [0.07692307692307687, 0.07692307692307687,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>naive_nbr</td>\n",
       "      <td>default</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{1: [0.07692307692307687, 0.07692307692307687,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>naive_nbr</td>\n",
       "      <td>default</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{1: [0.07692307692307687, 0.07692307692307687,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>naive_nbr</td>\n",
       "      <td>default</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{1: [0.07692307692307687, 0.07692307692307687,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>naive_degree</td>\n",
       "      <td>default</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{1: [0.07692307692307687, 0.07692307692307687,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>naive_degree</td>\n",
       "      <td>default</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{1: [0.07692307692307687, 0.07692307692307687,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>naive_degree</td>\n",
       "      <td>default</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{1: [0.07692307692307687, 0.46153846153846156,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>naive_degree</td>\n",
       "      <td>default</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{1: [0.07692307692307687, 0.6153846153846154, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>naive_degree</td>\n",
       "      <td>default</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{1: [0.6923076923076923, 0.6923076923076923, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           algo  dataset    p  \\\n",
       "0     naive_nbr  default  0.1   \n",
       "1     naive_nbr  default  0.2   \n",
       "2     naive_nbr  default  0.3   \n",
       "3     naive_nbr  default  0.4   \n",
       "4     naive_nbr  default  0.5   \n",
       "5  naive_degree  default  0.1   \n",
       "6  naive_degree  default  0.2   \n",
       "7  naive_degree  default  0.3   \n",
       "8  naive_degree  default  0.4   \n",
       "9  naive_degree  default  0.5   \n",
       "\n",
       "                                              result  \n",
       "0  {1: [0.07692307692307687, 0.07692307692307687,...  \n",
       "1  {1: [0.07692307692307687, 0.07692307692307687,...  \n",
       "2  {1: [0.07692307692307687, 0.07692307692307687,...  \n",
       "3  {1: [0.07692307692307687, 0.07692307692307687,...  \n",
       "4  {1: [0.07692307692307687, 0.07692307692307687,...  \n",
       "5  {1: [0.07692307692307687, 0.07692307692307687,...  \n",
       "6  {1: [0.07692307692307687, 0.07692307692307687,...  \n",
       "7  {1: [0.07692307692307687, 0.46153846153846156,...  \n",
       "8  {1: [0.07692307692307687, 0.6153846153846154, ...  \n",
       "9  {1: [0.6923076923076923, 0.6923076923076923, 0...  "
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "save = True\n",
    "\n",
    "group_list = ['algo', 'dataset', 'p']\n",
    "for key, item in df.groupby(group_list, as_index=False):\n",
    "    # there should be only one result\n",
    "    assert item.shape[0] == 1\n",
    "    \n",
    "    result = literal_eval(item['result'].iloc[0])\n",
    "    result = [(k, v) for k in result for v in result[k]]\n",
    "    result_df = pd.DataFrame(result, columns = ['core number', 'infected'])\n",
    "    \n",
    "    sns.barplot(x = 'core number', y = 'infected', data=result_df, palette='colorblind')\n",
    "    plt.xlabel('Core Number', fontsize=fontsize)\n",
    "    plt.ylabel(\"Fraction of Infected\", fontsize=fontsize)\n",
    "    plt.xticks(fontsize=labelsize)\n",
    "    plt.yticks(fontsize=labelsize)\n",
    "    plt.title(key)\n",
    "    plt.tight_layout()\n",
    "    filename = (\" \".join(map(str, key)) + \" propagation\").replace(\" \", \"_\").replace(\".\", \"\")\n",
    "    if(save):\n",
    "        plt.savefig(output_folder+\"fig/\" + filename + \".pdf\")\n",
    "    else:\n",
    "        print(filename)\n",
    "        plt.show()\n",
    "        break\n",
    "    plt.clf()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ]
}